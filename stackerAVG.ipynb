{
 "metadata": {
  "name": "",
  "signature": "sha256:3396ac2b5ae05c300a4522045ce863ae3f5c0e94e82d8346e41af1d61467cf36"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Averaging stacker"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import platform\n",
      "\n",
      "if platform.system() == 'Darwin':\n",
      "    xgboost_path = '/Users/andyh_mac/xgboost/xgboost-master/python'\n",
      "    number_threads = 8\n",
      "    data_dir = '/Users/andyh_mac/Desktop/Analytics/Higgs/data_std_2split/'\n",
      "elif platform.system() == 'Linux':\n",
      "    xgboost_path = '/home/ubuntu/xgboost-master/python'\n",
      "    number_threads = 32\n",
      "    data_dir = '/mnt2/Higgs/data_std_2split/'\n",
      "else:\n",
      "    print \"Don't know parameters for this system: %s\" % platform.system()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from hyperopt import fmin, rand, tpe, space_eval, hp, Trials\n",
      "from hyperopt import STATUS_OK, STATUS_FAIL\n",
      "from IPython.parallel import Client\n",
      "from pymongo import MongoClient\n",
      "from sklearn.linear_model import SGDRegressor as SGD\n",
      "from sklearn.preprocessing import normalize\n",
      "import higgs_lib\n",
      "import hyper_lib\n",
      "import numpy as np\n",
      "import math\n",
      "import pandas as pd\n",
      "import pickle\n",
      " \n",
      "# Load training data from Mongo\n",
      "print 'Loading training data from mongo higgs.data'\n",
      "client = MongoClient()\n",
      "db = client.higgs\n",
      "\n",
      "# Load X train,valid from Mongo\n",
      "def get_db(type):\n",
      "    # Find right record type\n",
      "    docs = db.data.find( { '$and' : [{'type': 'train'}, {'id': {'$regex': '01|02|03|21|23'}}] })   #use first 3 datasets\n",
      "    # Retreive the data set\n",
      "    train_data = []\n",
      "    valid_data = []\n",
      "    for d in docs:\n",
      "        train_data.append(d['stack_train'])\n",
      "        valid_data.append(d['stack_valid'])\n",
      "    # Convert train data to array\n",
      "    dim0= len(train_data[0])\n",
      "    dim1 = len(train_data)\n",
      "    X_train = np.empty((dim0,dim1))\n",
      "    for j,d in enumerate(train_data):\n",
      "        c = np.array(d)\n",
      "        X_train[:,j]=c\n",
      "    # Convert validation data to array\n",
      "    dim0= len(valid_data[0])\n",
      "    dim1 = len(valid_data)\n",
      "    X_valid = np.empty((dim0,dim1))\n",
      "    for j,d in enumerate(valid_data):\n",
      "        c = np.array(d)\n",
      "        X_valid[:,j]=c\n",
      "    return (X_train, X_valid)\n",
      "X_train, X_valid = get_db('train')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load Higgs csv files to get Y, W\n",
      "print 'Assigning data to numpy arrays.'\n",
      "Y_train = np.loadtxt( data_dir + 'Y_train_2.csv', delimiter=',', skiprows=1 )\n",
      "W_train = np.loadtxt( data_dir + 'W_train_2.csv', delimiter=',', skiprows=1 )\n",
      "Y_valid = np.loadtxt( data_dir + 'Y_valid_2.csv', delimiter=',', skiprows=1 )\n",
      "W_valid = np.loadtxt( data_dir + 'W_valid_2.csv', delimiter=',', skiprows=1 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Assigning data to numpy arrays.\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define objective (loss) function\n",
      "space = [ hp.quniform('threshold',60,90,1)]\n",
      "METHOD = 'mean'\n",
      "def my_obj(args):\n",
      "    threshold = args\n",
      "    threshold = int(threshold[0])\n",
      "\n",
      "    # Apply a stacking method\n",
      "    if METHOD == 'mean':\n",
      "        prob_predict_train = np.apply_along_axis(np.mean,1,X_train)\n",
      "        prob_predict_valid = np.apply_along_axis(np.mean,1,X_valid) \n",
      "    elif METHOD == 'geomean':\n",
      "        def p(x):\n",
      "            z=np.apply_along_axis(np.cumproduct,1,x)[:,-1]\n",
      "            return np.power(z, 1.0/x.shape[1])\n",
      "        prob_predict_train = p(X_train)\n",
      "        prob_predict_valid = p(X_valid)\n",
      "    else:\n",
      "        print 'METHOD must be mean or prob'\n",
      "        stop()\n",
      "        \n",
      "    # Choose cut point\n",
      "    pcut = np.percentile(prob_predict_train,threshold)\n",
      "     \n",
      "    # These are the final signal and background predictions\n",
      "    Yhat_train = prob_predict_train > pcut \n",
      "    Yhat_valid = prob_predict_valid > pcut\n",
      "\n",
      "    # Calc numeber of s and b TruePos and True Neg for training and validation\n",
      "    s_train, b_train = higgs_lib.count_s_b(W_train,Y_train,Yhat_train)\n",
      "    s_valid, b_valid = higgs_lib.count_s_b(W_valid,Y_valid,Yhat_valid)\n",
      "\n",
      "   \n",
      "    # Now calculate the invers AMS scores\n",
      "    def inv_AMSScore(s,b):\n",
      "        try:\n",
      "            inv_ams = 1/math.sqrt (2.*( (s + b + 10.)*math.log(1.+s/(b+10.))-s))\n",
      "        except:\n",
      "            inv_ams= 1\n",
      "            pass\n",
      "        return inv_ams\n",
      "    trial_results={}\n",
      "    trial_results['loss'] = inv_AMSScore(s_train,b_train)\n",
      "    trial_results['valid_loss'] = inv_AMSScore(s_valid,b_valid)\n",
      "    trial_results['status'] = STATUS_OK\n",
      "    return trial_results\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up hyperopt\n",
      "trials= Trials()\n",
      "hyperopt_iter =30\n",
      "print 'Training classifier (this may take some time!)'\n",
      "best = fmin(fn=my_obj, space=space, algo=rand.suggest, max_evals=hyperopt_iter, trials=trials)    \n",
      "print best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot trial results\n",
      "hyper_lib.plot_trials(trials)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inspect trial details\n",
      "hyper_lib.which_tid(25,trials)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Predict train and valid classes\n",
      "# Select threshold found in hyperopt\n",
      "best = {'threshold': 84.0}\n",
      "# Stack the inputs\n",
      "print 'Training classifier'\n",
      "threshold = int(best['threshold'])\n",
      "if METHOD == 'mean':\n",
      "    prob_predict_train = np.apply_along_axis(np.mean,1,X_train)\n",
      "    prob_predict_valid = np.apply_along_axis(np.mean,1,X_valid) \n",
      "elif METHOD == 'geomean':\n",
      "    def p(x):\n",
      "        z=np.apply_along_axis(np.cumproduct,1,x)[:,-1]\n",
      "        return np.power(z, 1.0/x.shape[1])\n",
      "    prob_predict_train = p(X_train)\n",
      "    prob_predict_valid = p(X_valid)\n",
      "else:\n",
      "    print 'METHOD must be mean or prob'\n",
      "    stop()\n",
      "        \n",
      "pcut = np.percentile(prob_predict_train,threshold)\n",
      " \n",
      "# This are the final signal and background predictions\n",
      "Yhat_train = prob_predict_train > pcut \n",
      "Yhat_valid = prob_predict_valid > pcut\n",
      " \n",
      "# Calc numeber of s and b TruePos and True Neg for training and validation\n",
      "s_train, b_train = higgs_lib.count_s_b(W_train,Y_train,Yhat_train)\n",
      "s_valid, b_valid = higgs_lib.count_s_b(W_valid,Y_valid,Yhat_valid)\n",
      " \n",
      "# Now calculate the AMS scores\n",
      "print 'Calculating AMS score for a probability cutoff pcut=',pcut\n",
      "print '   - AMS based on 90% training   sample:',higgs_lib.AMSScore(s_train,b_train)\n",
      "print '   - AMS based on 10% validation sample:',higgs_lib.AMSScore(s_valid,b_valid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot histogram of class probabilities for inspection\n",
      "plt.hist([prob_predict_valid[Y_valid==0.0],prob_predict_valid[Y_valid==1.0]], bins = 30, stacked=True,  color=[ 'Khaki', 'DarkOrange'])\n",
      "         "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now load the testing data, storing the data (X) and index (I)\n",
      "def get_db_test():\n",
      "    # Find right record type\n",
      "    docs = db.data.find( { '$and' : [{'type': 'test'}, {'id': {'$regex': '01|02|03|21|23|11|14'}}] })  #use first 3 datasets\n",
      "    # Retreive the data set\n",
      "    test_data = []\n",
      "    for d in docs:\n",
      "        test_data.append(d['stack_test'])\n",
      "    # Convert test data to array\n",
      "    dim0= len(test_data[0])\n",
      "    dim1 = len(test_data)\n",
      "    X_test = np.empty((dim0,dim1))\n",
      "    for j,d in enumerate(test_data):\n",
      "        c = np.array(d)\n",
      "        X_test[:,j]=c\n",
      "    return (X_test)\n",
      "\n",
      "print 'Loading testing data from mongo'\n",
      "data_test = np.loadtxt( 'test.csv', delimiter=',', skiprows=1 )\n",
      "X_raw = get_db_test()\n",
      "X_test = np.zeros(X_raw.shape)\n",
      "def proba(x): return 1.0/(1 + exp(-x))\n",
      "for i in range(X_raw.shape[1]):\n",
      "    if np.min(X_raw[:,i]) < 0 or np.max(X_raw[:,i]) > 1:\n",
      "        X_test[:,i] = apply_along_axis(proba,0,X_raw[:,i])\n",
      "    else:\n",
      "        X_test[:,i] = X_raw[:,i]\n",
      "I_test = list(data_test[:,0])\n",
      " \n",
      "# Get a vector of the probability predictions which will be used for the ranking\n",
      "print 'Building predictions'\n",
      "if METHOD == 'mean':\n",
      "    Predictions_test = np.apply_along_axis(np.mean,1,X_test)\n",
      "elif METHOD == 'geomean':\n",
      "    def p(x):\n",
      "        z=np.apply_along_axis(np.cumproduct,1,x)[:,-1]\n",
      "        return np.power(z, 1.0/x.shape[1])\n",
      "    Predictions_test = p(X_test)\n",
      "else:\n",
      "    print 'METHOD must be mean or prob'\n",
      "    stop()\n",
      "\n",
      "# Assign labels based the best pcut\n",
      "Label_test = list(Predictions_test>pcut)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now get the CSV data, using the probability prediction in place of the ranking\n",
      "print 'Organizing the prediction results'\n",
      "resultlist = []\n",
      "for x in range(len(I_test)):\n",
      "    resultlist.append([int(I_test[x]), Predictions_test[x], 's'*(Label_test[x]==1.0)+'b'*(Label_test[x]==0.0)])\n",
      " \n",
      "# Sort the result list by the probability prediction\n",
      "resultlist = sorted(resultlist, key=lambda a_entry: a_entry[1]) \n",
      " \n",
      "# Loop over result list and replace probability prediction with integer ranking\n",
      "for y in range(len(resultlist)):\n",
      "    resultlist[y][1]=y+1\n",
      " \n",
      "# Re-sort the result list according to the index\n",
      "resultlist = sorted(resultlist, key=lambda a_entry: a_entry[0])\n",
      " \n",
      "# Write the result list data to a csv file\n",
      "print 'Writing a final csv file Kaggle_higgs_prediction_output.csv'\n",
      "fcsv = open('Kaggle_higgs_prediction_output.csv','w')\n",
      "fcsv.write('EventId,RankOrder,Class\\n')\n",
      "for line in resultlist:\n",
      "    theline = str(line[0])+','+str(line[1])+','+line[2]+'\\n'\n",
      "    fcsv.write(theline) \n",
      "fcsv.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot histogram of Predictions for inspection\n",
      "plt.figure(2)\n",
      "sel1 = np.array(Label_test) == 1.0\n",
      "sel0 = np.logical_not(sel1)\n",
      "plt.hist( [np.array(Predictions_test)[sel0 ], np.array(Predictions_test)[sel1]], stacked=True, bins=30,color=['Khaki','DarkOrange'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compare number of predicted positives for test with number of postives in train\n",
      "print 'number of postives for test: %s' % sum(Label_test)\n",
      "print 'number of postives for train(normalized to test): %s' % str(sum(Yhat_train)*550000/(X_train.shape[0]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}